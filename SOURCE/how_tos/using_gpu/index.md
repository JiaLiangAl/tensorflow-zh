# 使用GPU <a class="md-anchor" id="AUTOGENERATED-using-gpus"></a>

## 支持的设备 <a class="md-anchor" id="AUTOGENERATED-supported-devices"></a>

在经典的系统中，会有多个计算设备。在TensorFlow内，支持的设置类型是`CPU`和`GPU`，它们被表示为 `字符串`。例如：

*  `"/cpu:0"`: 你机器上的CPU.
*  `"/gpu:0"`: 你机器上的GPU,如果你有一个的话.
*  `"/gpu:1"`: 你机器上的第二个 GPU，等等.

如果一个TensorFlow操作同时有CPU和GPU的实现，当这个操作配置到一个设备时GPU将会得到优先权。例如，`matmul` 同时有CPU和GPU的核，在一个有设备`cpu:0`和`gpu:0`的系统上，`gpu:0`将会被选择来执行`matmul`。

## 记录设备布置 <a class="md-anchor" id="AUTOGENERATED-logging-device-placement"></a>

要找出你的操作和张量分配到哪些设备，用`log_device_placement`设置为`True`来创建session。

```python
# Creates a graph.
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print sess.run(c)
```

你将看到如下输出：

```
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: Tesla K40c, pci bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/gpu:0
a: /job:localhost/replica:0/task:0/gpu:0
MatMul: /job:localhost/replica:0/task:0/gpu:0
[[ 22.  28.]
 [ 49.  64.]]

```

## 人工设置布置 <a class="md-anchor" id="AUTOGENERATED-manual-device-placement"></a>

如果你想在你选择的设备而不是自动选择的设备上执行某个特定的操作，你可以用`with tf.device` 来创建一个设备上下文这样所有在这个环境内的操作将拥有相同的设备配置。

```python
# Creates a graph.
with tf.device('/cpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print sess.run(c)
```

你将看到现在`a`和`b`被分配到`cpu:0`。

```
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: Tesla K40c, pci bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/cpu:0
a: /job:localhost/replica:0/task:0/cpu:0
MatMul: /job:localhost/replica:0/task:0/gpu:0
[[ 22.  28.]
 [ 49.  64.]]
```

## 在多GPU系统上使用单个GPU <a class="md-anchor" id="AUTOGENERATED-using-a-single-gpu-on-a-multi-gpu-system"></a>

如果在你的系统里有多个GPU，具有最小ID的一个将会被默认选中。如果你想在其他GPU上执行，你需要显示地指定参数。

```python
# Creates a graph.
with tf.device('/gpu:2'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print sess.run(c)
```

如果你已指定的设备不存在，你将得到一个 `InvalidArgumentError`:

```
InvalidArgumentError: Invalid argument: Cannot assign a device to node 'b':
Could not satisfy explicit device specification '/gpu:2'
   [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2]
   values: 1 2 3...>, _device="/gpu:2"]()]]
```

如果当指定的设备不存在时你想TensorFlow自动选择一个已存在且支持的设备去执行操作，你可以创建session时在配置选项里设置 `allow_soft_placement` 为 `True` 。

```python
# Creates a graph.
with tf.device('/gpu:2'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# Creates a session with allow_soft_placement and log_device_placement set
# to True.
sess = tf.Session(config=tf.ConfigProto(
      allow_soft_placement=True, log_device_placement=True))
# Runs the op.
print sess.run(c)
```

## 使用多CPU <a class="md-anchor" id="AUTOGENERATED-using-multiple-gpus"></a>

如果你想在多个GPU上执行TensorFlow，你可以构造一个每一层都分配到不同GPU的多层结构。
例如：

```
# Creates a graph.
c = []
for d in ['/gpu:2', '/gpu:3']:
  with tf.device(d):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])
    c.append(tf.matmul(a, b))
with tf.device('/cpu:0'):
  sum = tf.add_n(c)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print sess.run(sum)
```

你将看到如下输出：

```
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: Tesla K20m, pci bus
id: 0000:02:00.0
/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: Tesla K20m, pci bus
id: 0000:03:00.0
/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: Tesla K20m, pci bus
id: 0000:83:00.0
/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: Tesla K20m, pci bus
id: 0000:84:00.0
Const_3: /job:localhost/replica:0/task:0/gpu:3
Const_2: /job:localhost/replica:0/task:0/gpu:3
MatMul_1: /job:localhost/replica:0/task:0/gpu:3
Const_1: /job:localhost/replica:0/task:0/gpu:2
Const: /job:localhost/replica:0/task:0/gpu:2
MatMul: /job:localhost/replica:0/task:0/gpu:2
AddN: /job:localhost/replica:0/task:0/cpu:0
[[  44.   56.]
 [  98.  128.]]
```

[cifar10 tutorial](../../tutorials/deep_cnn/index.md)是一个演示怎样在多GPU上训练的好例子。
